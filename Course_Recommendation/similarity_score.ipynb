{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate Course Similarity using BoW Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity measurement between items is the foundation of many recommendation algorithms, especially for content-based recommendation algorithms. For example, if a new course is similar to user's enrolled courses, we could recommend that new similar course to the user. Or If user A is similar to user B, then we can recommend some of user B's courses to user A (the unseen courses) because user A and user B may have similar interests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectives\n",
    "- Calculate the similarity between any two courses using BoW feature vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous course, you learned many similarity measurements such as consine, jaccard index, or euclidean distance, and these methods need to work on either two vectors or two sets (sometimes even matrices or tensors).\n",
    "\n",
    "In previous labs, we extracted the BoW features from course textual content. Given the course BoW feature vectors, we can easily apply similarity measurement to calculate the course similarity as shown in the below figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/module_2/images/course_sim.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk==3.6.7\n",
    "#!pip install gensim==4.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import nltk as nltk\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import ngrams\n",
    "from gensim import corpora\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also set a random state\n",
    "rs = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we have two simple example courses:\n",
    "course1 = \"machine learning for everyone\"\n",
    "course2 = \"machine learning for beginners\"\n",
    "\n",
    "# tokenize them using the split() method \n",
    "# (or using word_tokenize() method provided in nltk\n",
    "tokens = set(course1.split() + course2.split())\n",
    "tokens = list(tokens)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate BoW features (token counts) for these two courses \n",
    "# (or using tokens_dict.doc2bow() method provided in nltk\n",
    "def generate_sparse_bow(course):\n",
    "    bow_vector = []\n",
    "    words = course.split()\n",
    "    for token in tokens:\n",
    "        if token in words:\n",
    "            bow_vector.append(1)\n",
    "        else:\n",
    "            bow_vector.append(0)\n",
    "    return bow_vector\n",
    "\n",
    "bow1 = generate_sparse_bow(course1)\n",
    "print(bow1)\n",
    "bow2 = generate_sparse_bow(course2)\n",
    "print(bow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the cosine similarity measurement on the two vectors:\n",
    "cos_sim = 1 - cosine(bow1, bow2)\n",
    "print(f\"The cosine similarity between course `{course1}` and course `{course2}` is {round(cos_sim, 2) * 100}%\")\n",
    "\n",
    "# Try similarity measurements \n",
    "# such as Euclidean Distance or Jaccard index.\n",
    "from scipy.spatial.distance import euclidean\n",
    "euc_sim = euclidean(bow1,bow2)-1\n",
    "euc_sim*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BoW features as Pandas dataframe\n",
    "bows_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/datasets/courses_bows.csv\"\n",
    "bows_df = pd.read_csv(bows_url)\n",
    "bows_df = bows_df[['doc_id', 'token', 'bow']]\n",
    "bows_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the course dataframe\n",
    "course_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/datasets/course_processed.csv\"\n",
    "course_df = pd.read_csv(course_url)\n",
    "course_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_df[course_df['COURSE_ID'] == 'ML0101ENv3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_course = bows_df[bows_df['doc_id'] == 'ML0101ENv3']\n",
    "ml_course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_courseT = ml_course.pivot(index=['doc_id'], columns='token').reset_index(level=[0])\n",
    "ml_courseT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_two_bows(basedoc, comparedoc):\n",
    "    base = basedoc.copy()\n",
    "    base['type'] = 'base'\n",
    "    compare = comparedoc.copy()\n",
    "    compare['type'] = 'compare'\n",
    "    # Append the two token sets vertically\n",
    "    join = base.append(compare)\n",
    "    # Pivot the two joined courses\n",
    "    joinT = join.pivot(index=['doc_id', 'type'], columns='token').fillna(0).reset_index(level=[0, 1])\n",
    "    # Assign columns\n",
    "    joinT.columns = ['doc_id', 'type'] + [t[1] for t in joinT.columns][2:]\n",
    "    return joinT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course1 = bows_df[bows_df['doc_id'] == 'ML0151EN']\n",
    "course2 = bows_df[bows_df['doc_id'] == 'ML0101ENv3']\n",
    "bow_vectors = pivot_two_bows(course1, course2)\n",
    "bow_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = 1 - cosine(bow_vectors.iloc[0, 2:], bow_vectors.iloc[1, 2:])\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE\n",
    "## For each course other than ML0101ENv3, use pivot_course_rows to convert it with course ML0101ENv3 into horizontal two BoW feature vectors\n",
    "## Then use the cosine method to calculate the similarity\n",
    "## Report all courses with similarities larger than a specific threshold (such as 0.5)\n",
    "for id in course_df['COURSE_ID'].unique():\n",
    "    base_course = bows_df[bows_df['doc_id'] == 'ML0101ENv3']\n",
    "    compare_course = bows_df[bows_df['doc_id'] == id]\n",
    "    bow_vectors = pivot_two_bows(base_course, compare_course)\n",
    "    similarity = 1 - cosine(bow_vectors.iloc[0, 2:], bow_vectors.iloc[1, 2:])\n",
    "    if 1 > similarity > 0.5:\n",
    "        print(f\"similarity score of {bow_vectors.iloc[0,0]} with {bow_vectors.iloc[1,0]} : {similarity*100}\")\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
